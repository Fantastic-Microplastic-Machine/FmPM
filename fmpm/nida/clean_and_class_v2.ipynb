{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libriaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional \n",
    "import torch.optim \n",
    "import torch.utils.data\n",
    "\n",
    "import torchvision.transforms\n",
    "import torchvision.datasets\n",
    "\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import sklearn.preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    \"\"\"sets seeds for several used packages\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_column(column):\n",
    "    \"\"\"\n",
    "    takes single columned Pandas DataFrame of categorical data and encodes it\n",
    "    into array of class binarys\n",
    "    \"\"\"\n",
    "    encoder = sklearn.preprocessing.OneHotEncoder()\n",
    "    shape_arr = encoder.fit_transform(column).toarray().astype(int)\n",
    "        \n",
    "    return list(shape_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(labels, image_root):\n",
    "    \"\"\"\n",
    "    Takes in raw labels dataframe and converts it into the format\n",
    "    expected for tenX_dataset class\n",
    "    \"\"\"\n",
    "\n",
    "    #Splitting description column into color and shape columns\n",
    "    new = labels[\"Description\"].str.split(\" \", n=1, expand=True)\n",
    "    labels.drop(columns=['Description'], inplace=True)\n",
    "    labels['Color'] = new[0].values\n",
    "    labels['Shape'] = new[1].values\n",
    "    \n",
    "    #Decomposing sample keywords into seperate strings\n",
    "    sample_names = labels[\"Sample\"].str.split(\" \", n=1, expand=False)\n",
    "    labels['Sample'] = sample_names\n",
    "    \n",
    "    #Converting identification into boolean for is/is not plastic\n",
    "    PLASTICS = ['polystyrene', 'polyethylene','polypropylene','Nylon','ink + plastic','PET','carbon fiber','poly(ethylene glycol) monooleate or polyamide resin']\n",
    "    identification = labels['Identification']\n",
    "    \n",
    "    for i in range(0,len(identification)):\n",
    "        if identification[i] in PLASTICS:\n",
    "            identification[i] = True\n",
    "        else:\n",
    "            identification[i] = False\n",
    "\n",
    "    labels['Identification']=identification\n",
    "    labels.rename(columns={'Identification': 'isPlastic'}, inplace=True)\n",
    "    labels['isPlastic'] = [i.astype(int) for i in encode_column(labels[[\"isPlastic\"]])]\n",
    "    \n",
    "    \n",
    "    #Encoding shape and color data\n",
    "    labels['Shape'] = encode_column(labels[['Shape']])\n",
    "    labels['Color'] = encode_column(labels[['Color']])\n",
    "    \n",
    "    labels = add_filenames(labels, image_root)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_filenames(labels, image_root):\n",
    "    \"\"\"\n",
    "    Replaces sample column of labels with the actual filename so that the dataset class doesn't have to do that work.\n",
    "    \"\"\"\n",
    "    image_filenames = os.listdir(image_root)\n",
    "    labels.insert(loc=1, column='File', value=None)\n",
    "    for index, row in labels.iterrows():\n",
    "        sample = row['Sample']\n",
    "        for fname in image_filenames:\n",
    "            str_id = '^' + ' '.join(row['Sample']) + ' .*'\n",
    "            result = re.search(str_id, fname)\n",
    "            if result:\n",
    "                image_file = result.group()\n",
    "                assert(os.path.exists('./data/images_10x/' + image_file))\n",
    "                break\n",
    "        else:\n",
    "            image_file = None\n",
    "        labels.loc[index, 'File'] = image_file\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nones(df):\n",
    "    \"\"\"further preps dataframe by removing nones, should probably move into prep_data\"\"\"\n",
    "    for index, row in df.iterrows():\n",
    "        if row['File'] == None:\n",
    "            df.drop(index, inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(labels_df, train_prop):\n",
    "    \"\"\"\n",
    "    Input: prepped and cleaned dataframe with image and corresponding\n",
    "    plastic/non-plastic identifications, desired proportion for training set (decimal between 0-1) \n",
    "    Returns: training dataframe with train_prop of the total data, and test_df with the remaining data\n",
    "    \"\"\"\n",
    "    split_ratio = 0.5\n",
    "    train_df = (labels_frame.sample(frac = train_prop))\n",
    "    test_df = (labels_frame.drop(train_df.index))\n",
    "\n",
    "    # reset index to avoid KeyErrors!\n",
    "    train_df = train_df.reset_index()\n",
    "    test_df = test_df.reset_index()\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs but may have bugs- net seems to only guess 1 or 0 no matter what\n",
    "\n",
    "def train_model(train_loader, network, optimizer, criterion, nepochs):\n",
    "    \"\"\"\n",
    "    This function trains a convolutional neural network.\n",
    "    Input: the training set data loader, defined network, optimizer , crtiterion, and number of epochs\n",
    "    Returns: trained neural network \n",
    "    \"\"\"\n",
    "    for epoch in range(nepochs):  # loop over the dataset\n",
    "        running_loss = 0.0\n",
    "    \n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "            #get the inputs and correspponding labels\n",
    "            inputs = data['image']\n",
    "            labels = data['plastic']\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs =  network(data['image'])\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    print('Finished Training')\n",
    "    return network \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tenX_dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Class inherited from torch Dataset. Required methods are, init,\n",
    "    len, and getitem.\n",
    "    \"\"\"\n",
    "    def __init__(self, labels_frame, image_dir, transform):\n",
    "        \"\"\"\n",
    "        initializes an instance of the class. Here we store 4 variables\n",
    "        in the class. Calling init just looks like dataset = tenX_dataset(lables, 'image_folder', transform).\n",
    "        \n",
    "        labels: altered version of csv file\n",
    "        image_dir: The file path to the folder the images are in\n",
    "        image_filenames: A list of all the image file names in the image folder\n",
    "        transform: A pytorch object. Works like a function. You call transform(x) and it performs\n",
    "                    a series of operations on x\n",
    "        \"\"\"\n",
    "        self.labels = labels_frame\n",
    "        self.image_dir = image_dir\n",
    "        self.image_filenames = os.listdir(self.image_dir)\n",
    "        self.transform = transform\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the length of the dataset\"\"\"\n",
    "        return len(self.labels)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a dictionary containing image and image data. Right now\n",
    "        it looks like: \n",
    "        sample = {'image': image, 'plastic': [0], 'shape':[0,0,0,0,0], 'color':[0,0,0,0,0]}\n",
    "        \"\"\"\n",
    "        image_filename = self.labels['File'][idx]\n",
    "        image = None\n",
    "             \n",
    "        if image_filename is not None:\n",
    "            image_filepath = os.path.join(self.image_dir, image_filename)\n",
    "            image = skimage.io.imread(image_filepath)\n",
    "            if self.transform is not None:\n",
    "                image = self.transform(image)\n",
    "\n",
    "        sample = {'image': image,\n",
    "                  'shape': self.labels['Shape'][idx],\n",
    "                  'color': self.labels['Color'][idx],\n",
    "                  'plastic': self.labels['isPlastic'][idx]}\n",
    "  \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_network(network, path):\n",
    "    \"\"\"\n",
    "    Saves trained neural network to a file\n",
    "    Input: trained network, path for saving (e.g. './trained_test1.pth')\n",
    "    Returns: None, saves network to the specified file \n",
    "    \"\"\"\n",
    "    PATH = path\n",
    "    torch.save(network.state_dict(), PATH)\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting first 20 images of dataset. Obviously getting quite a few duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# labels_filepath = 'data/10x_labels_more.csv'\n",
    "# image_dir = 'data/images_10x'\n",
    "# labels = prep_data(pd.read_csv(labels_filepath, delimiter='\\t'), image_dir)\n",
    "# tenX = tenX_dataset(labels, image_dir, None)\n",
    "\n",
    "\n",
    "# for i in range(len(tenX)):\n",
    "#     sample = tenX[i]\n",
    "#     plt.figure(i)\n",
    "#     if sample['image'] is not None:\n",
    "#         plt.imshow(sample['image'])\n",
    "#     if i>20:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things to improve/fix\n",
    "* Make sure the nonetypes are because the file actually isn't in my folder of images\n",
    "* Code for normalizing image data\n",
    "* Image augmentation. Probably want to cut off some of the edges to get rid of number stuff and decrease extraneous information. The think we actually care about is only occupying like 5-10% of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN \n",
    "\n",
    "starting from simple test network lik eher:https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds - for reproducibility\n",
    "set_seeds(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the transform for the image\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToPILImage(),\n",
    "                                             torchvision.transforms.RandomRotation((-180,180)),\n",
    "                                             torchvision.transforms.CenterCrop((300, 350)),\n",
    "                                             torchvision.transforms.ToTensor()\n",
    "                                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data and split into test and train DataFrames\n",
    "image_dir = 'data/images_10x'\n",
    "raw_frame = pd.read_csv('data/10x_test1.csv', delimiter='\\t')\n",
    "labels_frame = remove_nones(prep_data(pd.read_csv('data/10x_test1.csv', delimiter='\\t'), image_dir))\n",
    "train_df, test_df = split_train_test(labels_frame, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>File</th>\n",
       "      <th>Sample origin</th>\n",
       "      <th>Size (um)</th>\n",
       "      <th>isPlastic</th>\n",
       "      <th>Color</th>\n",
       "      <th>Shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Sample                              File Sample origin  \\\n",
       "0           [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "1           [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "2           [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "3           [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "4           [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "5           [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "6           [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "7           [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "8           [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "9           [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "10          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "11          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "12          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "13          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "14          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "15          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "16          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "17          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "18          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "19          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "20          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "21          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "22          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "23          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "24          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "25  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "26  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "27  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "28  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "29  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "30  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "31  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "32  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "33  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "34  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "35  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "36  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "37  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "38  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "39  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "40  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "41  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "42  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "43  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "44  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "45  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "46  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "47  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "48  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "49  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "\n",
       "    Size (um) isPlastic      Color      Shape  \n",
       "0         100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "1         100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "2         100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "3         100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "4         100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "5         100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "6         100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "7         100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "8         100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "9         100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "10        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "11        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "12        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "13        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "14        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "15        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "16        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "17        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "18        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "19        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "20        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "21        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "22        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "23        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "24        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "25        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "26        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "27        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "28        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "29        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "30        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "31        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "32        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "33        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "34        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "35        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "36        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "37        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "38        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "39        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "40        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "41        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "42        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "43        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "44        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "45        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "46        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "47        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "48        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "49        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>File</th>\n",
       "      <th>Sample origin</th>\n",
       "      <th>Size (um)</th>\n",
       "      <th>isPlastic</th>\n",
       "      <th>Color</th>\n",
       "      <th>Shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[20200817, 110_3]</td>\n",
       "      <td>20200817 110_3 - 10x.bmp</td>\n",
       "      <td>mussels</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[20191004, Set3Sample3_4]</td>\n",
       "      <td>20191004 Set3Sample3_4 - 10x.bmp</td>\n",
       "      <td>orcas</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Sample                              File Sample origin  \\\n",
       "0           [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "1           [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "2           [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "3           [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "4           [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "5           [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "6           [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "7           [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "8           [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "9           [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "10          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "11          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "12          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "13          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "14          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "15          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "16          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "17          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "18          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "19          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "20          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "21          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "22          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "23          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "24          [20200817, 110_3]          20200817 110_3 - 10x.bmp       mussels   \n",
       "25  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "26  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "27  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "28  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "29  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "30  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "31  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "32  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "33  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "34  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "35  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "36  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "37  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "38  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "39  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "40  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "41  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "42  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "43  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "44  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "45  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "46  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "47  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "48  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "49  [20191004, Set3Sample3_4]  20191004 Set3Sample3_4 - 10x.bmp         orcas   \n",
       "\n",
       "    Size (um) isPlastic      Color      Shape  \n",
       "0         100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "1         100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "2         100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "3         100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "4         100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "5         100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "6         100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "7         100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "8         100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "9         100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "10        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "11        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "12        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "13        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "14        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "15        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "16        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "17        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "18        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "19        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "20        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "21        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "22        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "23        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "24        100    [1, 0]  [0, 0, 1]  [1, 0, 0]  \n",
       "25        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "26        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "27        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "28        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "29        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "30        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "31        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "32        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "33        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "34        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "35        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "36        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "37        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "38        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "39        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "40        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "41        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "42        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "43        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "44        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "45        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "46        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "47        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "48        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  \n",
       "49        100    [0, 1]  [0, 1, 0]  [0, 0, 1]  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-17fe408da0ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtenX_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtenX_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transform' is not defined"
     ]
    }
   ],
   "source": [
    "train_set = tenX_dataset(train_df, image_dir, transform = transform)\n",
    "test_set = tenX_dataset(test_df, image_dir, transform = transform)\n",
    "\n",
    "batch_size = 1\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d6be023a6119>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(len(trainloader))\n",
    "print(len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "15\n",
      "35\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(len(trainloader))\n",
    "print(len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "        #self.pool = torch.nn.MaxPool2d(3, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(72576, 6)\n",
    "        self.fc2 = nn.Linear(6, 6)\n",
    "        self.fc3 = nn.Linear(6,2)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.max_pool2d(x, kernel_size = 2)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.max_pool2d(x, kernel_size = 2)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)    \n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)    \n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc3(x) \n",
    "       # x = nn.functional.sigmoid(x)\n",
    "#         x = self.pool(torch.nn.functional.relu(self.conv1(x)))\n",
    "#         x = self.pool(torch.nn.functional.relu(self.conv2(x)))\n",
    "#         x = x.view(x.shape[0], -1)\n",
    "#         x = nn.functional.relu(self.fc1(x))\n",
    "#         x = nn.functional.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0595, -0.1905]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0, 1]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Float but got scalar type Long for argument #2 'target' in call to _thnn_mse_loss_forward",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-282-9f63e6b1bc4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/fmpm/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/fmpm/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/fmpm/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2202\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2204\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2205\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Float but got scalar type Long for argument #2 'target' in call to _thnn_mse_loss_forward"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        inputs = data['image']\n",
    "        labels = data['plastic']\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        #optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs =  net(data['image'])\n",
    "        print(outputs)\n",
    "        print(labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(net.conv1.weight.grad) \n",
    "        print(loss)\n",
    "        #print(net.conv2.bias.grad[3])\n",
    "\n",
    "        # print statistics\n",
    "        #running_loss += loss.item()\n",
    "        #if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "        #    print('[%d, %5d] loss: %.3f' %\n",
    "        #          (epoch + 1, i + 1, running_loss / 2000))\n",
    "        #    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction  tensor([0])\n",
      "labels tensor([[1., 0.]], dtype=torch.float64)\n",
      "prediction  tensor([0])\n",
      "labels tensor([[1., 0.]], dtype=torch.float64)\n",
      "prediction  tensor([0])\n",
      "labels tensor([[0., 1.]], dtype=torch.float64)\n",
      "prediction  tensor([0])\n",
      "labels tensor([[0., 1.]], dtype=torch.float64)\n",
      "prediction  tensor([0])\n",
      "labels tensor([[0., 1.]], dtype=torch.float64)\n",
      "prediction  tensor([0])\n",
      "labels tensor([[1., 0.]], dtype=torch.float64)\n",
      "prediction  tensor([0])\n",
      "labels tensor([[1., 0.]], dtype=torch.float64)\n",
      "prediction  tensor([0])\n",
      "labels tensor([[0., 1.]], dtype=torch.float64)\n",
      "prediction  tensor([0])\n",
      "labels tensor([[1., 0.]], dtype=torch.float64)\n",
      "prediction  tensor([0])\n",
      "labels tensor([[0., 1.]], dtype=torch.float64)\n",
      "prediction  tensor([0])\n",
      "labels tensor([[0., 1.]], dtype=torch.float64)\n",
      "prediction  tensor([0])\n",
      "labels tensor([[0., 1.]], dtype=torch.float64)\n",
      "prediction  tensor([0])\n",
      "labels tensor([[0., 1.]], dtype=torch.float64)\n",
      "prediction  tensor([0])\n",
      "labels tensor([[0., 1.]], dtype=torch.float64)\n",
      "prediction  tensor([0])\n",
      "labels tensor([[1., 0.]], dtype=torch.float64)\n",
      "Accuracy of the network on the 15 test images: 100 %\n"
     ]
    }
   ],
   "source": [
    "save_network(net, './trained_test1.pth')\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images = dataiter.next()['image']\n",
    "labels = dataiter.next()['plastic']\n",
    "\n",
    "outputs = net(images)\n",
    "outputs\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images = data['image']\n",
    "        labels = data['plastic']\n",
    "        outputs = net(images)\n",
    "        #print(data['plastic'])\n",
    "        predicted = torch.max(outputs.data, 1)[1]\n",
    "        print('prediction ', predicted)\n",
    "        print('labels', labels)\n",
    "        #print(outputs.data)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the %d test images: %d %%' % (len(testloader),\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try a different model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetTwo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetTwo, self).__init__()\n",
    "        # convolutional layer\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        # max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(193536, 256)\n",
    "        self.fc2 = nn.Linear(256, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1,193536 )\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.dropout(nn.functional.relu(self.fc2(x)))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "model = NetTwo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetTwo(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc1): Linear(in_features=193536, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=2, bias=True)\n",
      "  (softmax): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = NetTwo()\n",
    "# defining the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.07)\n",
    "# defining the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tenX_dataset(train_df, image_dir, transform = transform)\n",
    "test_set = tenX_dataset(test_df, image_dir, transform = transform)\n",
    "\n",
    "batch_size = 1\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NetTwo(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc1): Linear(in_features=193536, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=2, bias=True)\n",
       "  (softmax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nepochs = 15\n",
    "train_model(trainloader, model, optimizer, criterion, nepochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 1, 0, 1])\n",
      "prediction  tensor([0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 1, 0])\n",
      "prediction  tensor([0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 1, 1])\n",
      "prediction  tensor([0, 0, 0, 0, 0])\n",
      "Accuracy of the network on the 3 test images: 40 %\n"
     ]
    }
   ],
   "source": [
    "save_network(model, './trained_test2.pth')\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images = dataiter.next()['image']\n",
    "labels = dataiter.next()['plastic']\n",
    "\n",
    "outputs = net(images)\n",
    "outputs\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images = data['image']\n",
    "        labels = data['plastic']\n",
    "        outputs = net(images)\n",
    "        print(data['plastic'])\n",
    "        predicted = torch.max(outputs.data, 1)[1]\n",
    "        print('prediction ', predicted)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the %d test images: %d %%' % (len(testloader),\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying config 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetThree(\n",
       "  (block1): Sequential(\n",
       "    (0): Conv2d(3, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout2d(p=0.1, inplace=False)\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout2d(p=0.1, inplace=False)\n",
       "  )\n",
       "  (block3): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout2d(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lastcnn): Conv2d(64, 2, kernel_size=(56, 56), stride=(1, 1))\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NetThree(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetThree, self).__init__()\n",
    "        self.block1 = self.conv_block(c_in=3, c_out=256, dropout=0.1, kernel_size=5, stride=1, padding=2)\n",
    "        self.block2 = self.conv_block(c_in=256, c_out=128, dropout=0.1, kernel_size=3, stride=1, padding=1)\n",
    "        self.block3 = self.conv_block(c_in=128, c_out=64, dropout=0.1, kernel_size=3, stride=1, padding=1)\n",
    "        self.lastcnn = nn.Conv2d(in_channels=64, out_channels=2, kernel_size=56, stride=1, padding=0)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.lastcnn(x)\n",
    "        return x\n",
    "    def conv_block(self, c_in, c_out, dropout,  **kwargs):\n",
    "        seq_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=c_in, out_channels=c_out, **kwargs),\n",
    "            nn.BatchNorm2d(num_features=c_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=dropout)\n",
    "        )\n",
    "        return seq_block\n",
    "net3= NetThree()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net3.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_tag, dim = 1)\n",
    "    correct_results_sum = (y_pred_tags == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}\n",
    "loss_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-0455275b7a16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/fmpm/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/fmpm/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 916\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/fmpm/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2007\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2009\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/fmpm/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Begin training.\")\n",
    "for e in (range(1, 21)):\n",
    "    # TRAINING\n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "    model.train()\n",
    "    for X in trainloader:\n",
    "        X_train_batch = X['image'].to(device)\n",
    "        y_train_batch = X['plastic'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_train_pred = model(X_train_batch).squeeze()\n",
    "        train_loss = criterion(y_train_pred, y_train_batch)\n",
    "        train_acc = binary_acc(y_train_pred, y_train_batch)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_epoch_loss += train_loss.item()\n",
    "        train_epoch_acc += train_acc.item()\n",
    "    # VALIDATION\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_epoch_loss = 0\n",
    "        val_epoch_acc = 0\n",
    "        for X in testloader:\n",
    "            X_val_batch = X['image'].to(device)\n",
    "            y_val_batch = X['plastic'].to(device)\n",
    "            y_val_pred = model(X_val_batch).squeeze()\n",
    "            y_val_pred = torch.unsqueeze(y_val_pred, 0)\n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "            val_acc = binary_acc(y_val_pred, y_val_batch)\n",
    "            val_epoch_loss += train_loss.item()\n",
    "            val_epoch_acc += train_acc.item()\n",
    "    loss_stats['train'].append(train_epoch_loss/len(trainloader))\n",
    "    loss_stats['val'].append(val_epoch_loss/len(val_loader))\n",
    "    accuracy_stats['train'].append(train_epoch_acc/len(trainloader))\n",
    "    accuracy_stats['val'].append(val_epoch_acc/len(testloader))\n",
    "    print(f'Epoch {e+0:02}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(testloader):.5f} | Train Acc: {train_epoch_acc/len(trainloader):.3f}| Val Acc: {val_epoch_acc/len(testloader):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This transform just resizes the images to 3,480,752. So 3 for red green blue then height of 480\n",
    "#and width of 752. \n",
    "#transform = torchvision.transforms.Compose([\n",
    " #                           torchvision.transforms.ToPILImage(),\n",
    " #                           torchvision.transforms.Resize((480, 752)),\n",
    "   #                         torchvision.transforms.ToTensor()\n",
    "  #                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define image directory and cleaned up dataframe\n",
    "image_dir = 'data/images_10x'\n",
    "labels_frame = remove_nones(prep_data(pd.read_csv('data/10x_plastic_bias.csv', delimiter='\\t'), image_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tenX = tenX_dataset(labels_frame, image_dir, transform = transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of me trying to plug into cnn\n",
    "\n",
    "Most of the code came from this tutorial: https://github.com/bentrevett/pytorch-image-classification/blob/master/2_lenet.ipynb\n",
    "\n",
    "I was just trying to get this to work so I won't understand it as much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'data/images_10x'\n",
    "labels_frame = labels\n",
    "\n",
    "#This transform just resizes the images to 3,480,752. So 3 for red green blue then height of 480\n",
    "#and width of 752. \n",
    "transform = torchvision.transforms.Compose([\n",
    "                            torchvision.transforms.ToPILImage(),\n",
    "                            torchvision.transforms.Resize((480, 752)),\n",
    "                            torchvision.transforms.ToTensor()\n",
    "                                      ])\n",
    "\n",
    "\n",
    "train_data = tenX_dataset(labels_frame, image_dir, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'data/images_10x'\n",
    "labels_frame = remove_nones(prep_data(pd.read_csv('data/10x_labels_more.csv', delimiter='\\t'), image_dir))\n",
    "transform = torchvision.transforms.Compose([\n",
    "                            torchvision.transforms.ToPILImage(),\n",
    "                            torchvision.transforms.Resize((480, 752)),\n",
    "                            torchvision.transforms.ToTensor()\n",
    "                                      ])\n",
    "\n",
    "\n",
    "train_data = tenX_dataset(labels_frame, image_dir, transform = transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting into train/validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.9\n",
    "\n",
    "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, valid_data = torch.utils.data.random_split(train_data, \n",
    "                                           [n_train_examples, n_valid_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declaring iterator. The thing that will loop through our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "\n",
    "train_iterator = torch.utils.data.DataLoader(train_data, \n",
    "                                 shuffle = True, \n",
    "                                 batch_size = BATCH_SIZE)\n",
    "\n",
    "valid_iterator = torch.utils.data.DataLoader(valid_data, \n",
    "                                 batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The CNN archetecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        \"\"\"\n",
    "        Initializes CNN. Here we just define layer shapes that we call in the forward func\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        #Convulution layer 1. \n",
    "        #3 input channels (for three images Red, Green, Blue)\n",
    "        #6 output channels (I THINK this means we are applying two different filters to each image\n",
    "        #3 images, two filters each, we end up with 6 'images')\n",
    "        #kernel size is I THINK telling the filters took filter each set of 5 pixels into one.\n",
    "        #So are images will shrink a little as the edges get cut off\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, \n",
    "                               out_channels = 6, \n",
    "                               kernel_size = 5)\n",
    "        \n",
    "        #Convultion layer 2. See above\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, \n",
    "                               out_channels = 12, \n",
    "                               kernel_size = 5)\n",
    "        \n",
    "        #Linear layers. These probably arent complicated but I don't follow haha\n",
    "        #I think it turning the 259740 pixel values into 6 values. Then the second layers\n",
    "        #Turns the 6 into a different 6? and then 6 into 2. I'm not sure why 2 and not 1.\n",
    "        #Seeing as the output should be a number between 0-1. Closer to 0 = not plastic,\n",
    "        #closer to 1 = plastic. But I got errors about not having enough classes when\n",
    "        #I only had 1 output neuron.\n",
    "        #TBH these linear layers I just changed based on the error messages I got.\n",
    "        self.fc_1 = nn.Linear(259740, 6)\n",
    "        self.fc_2 = nn.Linear(6, 6)\n",
    "        self.fc_3 = nn.Linear(6, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Function that performs all the neural network forward calculation i.e.\n",
    "        takes image data from the input of the neural network to the output\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "    \n",
    "        #Gonna have to look at tutorial link.\n",
    "        x = nn.functional.max_pool2d(x, kernel_size = 2)\n",
    "        \n",
    "        x = nn.functional.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "                \n",
    "        x = nn.functional.max_pool2d(x, kernel_size = 2)\n",
    "        \n",
    "        x = nn.functional.relu(x)\n",
    "        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "                \n",
    "        h = x\n",
    "        \n",
    "        x = self.fc_1(x)\n",
    "                \n",
    "        x = nn.functional.relu(x)\n",
    "\n",
    "        x = self.fc_2(x)\n",
    "                \n",
    "        x = nn.functional.relu(x)\n",
    "\n",
    "        x = self.fc_3(x)\n",
    "        \n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instancing model, loss criteria, device to perform calculations on, and optimizer.\n",
    "OUTPUT_DIM = 1\n",
    "model = LeNet(OUTPUT_DIM)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Telling the model and loss function to do math on whatever device is\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    \"\"\"\n",
    "    Function calculate accuracy. See tutorial, may not\n",
    "    even be accurate for our model but it at least runs\n",
    "    \"\"\"\n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "    \"\"\"\n",
    "    Training loop. Takes data through NN calculates loss and adjusts NN. Repeat\n",
    "    \"\"\"\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    #Need to add logic to skip iteration if image is None\n",
    "    for sample in iterator:  \n",
    "        \n",
    "        image = sample['image'].to(device)\n",
    "        isPlastic = sample['plastic'].to(device)\n",
    "                \n",
    "        optimizer.zero_grad()      \n",
    "        y_pred, what = model(image)\n",
    "\n",
    "        loss = criterion(y_pred, isPlastic)\n",
    "        acc = calculate_accuracy(y_pred, isPlastic)\n",
    "        loss.backward()    \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here the model is actually trained\n",
    "EPOCHS = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    start_time = time.monotonic()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "\n",
    "    \n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    #epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    #print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    #print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_network(network, path):\n",
    "    \"\"\"\n",
    "    Saves trained neural network to a file\n",
    "    Input: trained network, path for saving (e.g. './trained_test1.pth')\n",
    "    Returns: None, saves network to the specified file \n",
    "    \"\"\"\n",
    "    PATH = path\n",
    "    torch.save(network.state_dict(), PATH)\n",
    "    return None\n",
    "\n",
    "save_network()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
