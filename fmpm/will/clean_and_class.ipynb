{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ahead-disclosure",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e2845cbe8b5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional \n",
    "import torch.optim \n",
    "import torch.utils.data\n",
    "\n",
    "import torchvision.transforms\n",
    "import torchvision.datasets\n",
    "import torch.utils.data \n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-pointer",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-butterfly",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_filepath = 'data/10x_labels.csv'\n",
    "labels=pd.read_csv(labels_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-version",
   "metadata": {},
   "source": [
    "### Splitting Description column into shape and color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "new= labels[\"Description\"].str.split(\" \", n = 1, expand = True)\n",
    "labels.drop(columns=['Description'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['Color'] = new[0].values\n",
    "labels['Shape'] = new[1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-vacuum",
   "metadata": {},
   "source": [
    "### Decomposing Sample Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = labels[\"Sample\"].str.split(\" \", n = 1, expand = False)\n",
    "\n",
    "sample_names_frame = pd.DataFrame(sample_names)\n",
    "\n",
    "        \n",
    "        \n",
    "labels['Sample'] = sample_names_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-sleeping",
   "metadata": {},
   "source": [
    "### Changing Identification to boolean is or is not plastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['Identification'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "plastics = ['polystyrene', 'polyethylene','polypropylene','Nylon','ink + plastic','PET','carbon fiber']\n",
    "identification = labels['Identification']\n",
    "\n",
    "for i in range(0,len(identification)):\n",
    "    if identification[i] in plastics:\n",
    "        identification[i] = True\n",
    "    else:\n",
    "        identification[i] = False\n",
    "    \n",
    "labels['Identification']=identification\n",
    "labels.rename(columns={'Identification': 'isPlastic'}, inplace=True)\n",
    "labels.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-bundle",
   "metadata": {},
   "source": [
    "### Shape/isPlastic/Color Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['isPlastic'] = labels[\"isPlastic\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['Color'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-float",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_encoder.fit_transform(labels[['Shape']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_encoder.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_encoder = OneHotEncoder()\n",
    "shape_encoder.fit_transform(labels[['Color']]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-bandwidth",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tenX_dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    #Initializes dataset. Is only used once during the creating on a 'tenX_dataset' class\n",
    "    #transform is an optional parameter, it defaults to none if nothing is passed into the class\n",
    "    def __init__(self, labels_frame, image_dir, transform = None):\n",
    "        'Initialization'\n",
    "        self.labels = labels_frame\n",
    "        self.image_dir = image_dir\n",
    "        self.image_filenames = os.listdir(self.image_dir)\n",
    "        self.transform = None\n",
    "        \n",
    "    #Length of dataset\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    #Return an single image with labels based on given index\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.labels['Sample'][idx]\n",
    "        image_file = None\n",
    "        image = None\n",
    "        \n",
    "        for filename in self.image_filenames:\n",
    "            if len(image_id) == 1:\n",
    "                if image_id[0] in filename:\n",
    "                    #print(image_id)\n",
    "                    image_file = filename\n",
    "                    break\n",
    "            else:\n",
    "                if image_id[0] in filename and image_id[1] in filename:\n",
    "                    #print(image_id)\n",
    "                    image_file = filename\n",
    "                    break\n",
    "                \n",
    "        if not image_file:\n",
    "            #raise Exception('Could not find image file')\n",
    "            image_file = self.image_filenames[0]\n",
    "            image_filepath = os.path.join(self.image_dir, image_file)\n",
    "            image = skimage.io.imread(image_filepath)\n",
    "            sample = {'image': image,\n",
    "                'shape': self.labels['Shape'][idx],\n",
    "                'color': self.labels['Color'][idx],\n",
    "                'plastic': self.labels['isPlastic'][idx]}\n",
    "            \n",
    "            return sample\n",
    "        \n",
    "        \n",
    "        image_filepath = os.path.join(self.image_dir, image_file)\n",
    "        image = skimage.io.imread(image_filepath)\n",
    "        \n",
    "        sample = {'image': image,\n",
    "                'shape': self.labels['Shape'][idx],\n",
    "                'color': self.labels['Color'][idx],\n",
    "                'plastic': self.labels['isPlastic'][idx]}\n",
    "            \n",
    "        #This 'transform' will be where we specify how we edit the images (resize, \n",
    "        #change file type, data augmentation). It is defined outside this classs.\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "\n",
    "        return sample\n",
    "                \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'data/images_10x'\n",
    "labels_frame = labels\n",
    "transform = torchvision.transforms.Compose([\n",
    "                            torchvision.transforms.Resize(256),\n",
    "                            torchvision.transforms.ToTensor(),\n",
    "                                      ])\n",
    "\n",
    "\n",
    "tenX_dataset = tenX_dataset(labels_frame, image_dir, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-certificate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tenX_dataset.image_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=[]\n",
    "for i in range(len(tenX_dataset)):\n",
    "    sample = tenX_dataset[i]\n",
    "    samples.append(sample['image'])\n",
    "    if i>10:\n",
    "        break\n",
    "\n",
    "#samples\n",
    "#samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for im in samples:\n",
    "    if type(im) != type(None):\n",
    "        plt.figure(count)\n",
    "        plt.imshow(im)\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(samples[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-european",
   "metadata": {},
   "source": [
    "# Things to improve/fix\n",
    "* if data is for sure consistent. Take datacleaning steps, generalize, and put into a function. Then 10x_dataset class with get passed in the filename of the labels and in the init method the dataclean function should be called.\n",
    "* Verify the labels are coming through (i.e. train some sort of model on this data\n",
    "* Make sure the nonetypes are because the file actually isn't in my folder of images\n",
    "* 252_1 is displayign 252_10 because of way code is written. \n",
    "* One hot encode categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tenX_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_of_dataset(image_dataset):\n",
    "    \"\"\"\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_std_of_dataset(image_dataset):\n",
    "    \"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_labels(label_frame):\n",
    "    \"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, \n",
    "                               out_channels = 6, \n",
    "                               kernel_size = 5)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, \n",
    "                               out_channels = 16, \n",
    "                               kernel_size = 5)\n",
    "        \n",
    "        self.fc_1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc_2 = nn.Linear(120, 84)\n",
    "        self.fc_3 = nn.Linear(84, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #x = [batch size, 1, 28, 28]\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        #x = [batch size, 6, 24, 24]\n",
    "        \n",
    "        x = F.max_pool2d(x, kernel_size = 2)\n",
    "        \n",
    "        #x = [batch size, 6, 12, 12]\n",
    "        \n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        #x = [batch size, 16, 8, 8]\n",
    "        \n",
    "        x = F.max_pool2d(x, kernel_size = 2)\n",
    "        \n",
    "        #x = [batch size, 16, 4, 4]\n",
    "        \n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        #x = [batch size, 16*4*4 = 256]\n",
    "        \n",
    "        h = x\n",
    "        \n",
    "        x = self.fc_1(x)\n",
    "        \n",
    "        #x = [batch size, 120]\n",
    "        \n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc_2(x)\n",
    "        \n",
    "        #x = batch size, 84]\n",
    "        \n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc_3(x)\n",
    "\n",
    "        #x = [batch size, output dim]\n",
    "        \n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 1\n",
    "\n",
    "model = LeNet(OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for (x, y) in iterator:\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        y_pred, _ = model(x)\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "\n",
    "train_iterator = torch.utils.data.DataLoader(tenX_dataset, \n",
    "                                 shuffle = True, \n",
    "                                 batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    start_time = time.monotonic()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "\n",
    "    \n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-marsh",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
