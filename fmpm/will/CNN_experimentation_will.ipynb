{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "editorial-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import construct\n",
    "import prep\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "charming-connection",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Will/GradSchool/CHEME/Project/FmPM/fmpm/will/prep.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  identification[i] = False\n",
      "/Users/Will/GradSchool/CHEME/Project/FmPM/fmpm/will/prep.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  identification[i] = True\n"
     ]
    }
   ],
   "source": [
    "image_dir = 'data/10x'\n",
    "labels_file = 'data/me.csv'\n",
    "\n",
    "DATA = prep.prep_data(pd.read_csv(labels_file), image_dir)\n",
    "\n",
    "transforms = torchvision.transforms.Compose([\n",
    "                            torchvision.transforms.ToPILImage(),\n",
    "                            torchvision.transforms.RandomRotation((-180,180)),\n",
    "                            torchvision.transforms.CenterCrop((325)),\n",
    "                            torchvision.transforms.ToTensor()\n",
    "                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "south-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes CNN. Here we just define layer shapes that we call in the forward func\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels = 3, \n",
    "                               out_channels = 6, \n",
    "                               kernel_size = 5)\n",
    "                \n",
    "        #Convultion layer 2. See above\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels = 6, \n",
    "                               out_channels = 12, \n",
    "                               kernel_size = 5)\n",
    "        \n",
    "        self.fc_1 = torch.nn.Linear(39 * 39 * 12, 256)\n",
    "        self.fc_2 = torch.nn.Linear(256, 2)\n",
    "        self.drop = torch.nn.Dropout(p=.2)\n",
    "        self.batch1 = torch.nn.BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.batch2 = torch.nn.BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Function that performs all the neural network forward calculation i.e.\n",
    "        takes image data from the input of the neural network to the output\n",
    "        \"\"\"\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, kernel_size = 2)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, kernel_size = 4)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = x.view(x.shape[0], -1)  \n",
    "        x = self.fc_1(x) \n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc_2(x) \n",
    "        return x\n",
    "\n",
    "model = myModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "greater-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring iterator. The thing that will loop through our dataset.\n",
    "\n",
    "data = prep.tenX_dataset(DATA, 'data/10x', transform=transforms)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test, train = torch.utils.data.random_split(data, [int(.15*len(data)), len(data)-int(.15*len(data))])\n",
    "BATCH_SIZE = 32\n",
    "epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cooperative-context",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0, acc: 0.7495039701461792, loss: 5.826170656416151\n",
      "tensor([[  1.3418,   2.0230],\n",
      "        [ 15.1528, -26.2446],\n",
      "        [  7.7074,  -9.8131],\n",
      "        [ -2.4488,   1.5040],\n",
      "        [  4.4918,  -2.1442],\n",
      "        [ 10.4643, -14.4138],\n",
      "        [  0.9801,   0.8238]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "EPOCH: 1, acc: 0.7847222222222222, loss: 0.6980671903325452\n",
      "EPOCH: 2, acc: 0.8015873034795126, loss: 0.7744539562198851\n",
      "EPOCH: 3, acc: 0.8576388888888888, loss: 0.3752673765023549\n",
      "EPOCH: 4, acc: 0.848710318406423, loss: 0.39321037630240124\n",
      "EPOCH: 5, acc: 0.8715277777777778, loss: 0.31987442407343125\n",
      "tensor([[  1.7943, -18.0507],\n",
      "        [  0.5911, -13.1254],\n",
      "        [  3.2723,  -0.5083],\n",
      "        [  1.0217,  -0.7675],\n",
      "        [ -0.2604,   0.7032],\n",
      "        [ -0.3351,  -3.2899],\n",
      "        [  0.5031,   1.2254]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]])\n",
      "EPOCH: 6, acc: 0.8834325406286452, loss: 0.3104419625467724\n",
      "EPOCH: 7, acc: 0.848710318406423, loss: 0.2945644044213825\n",
      "EPOCH: 8, acc: 0.8819444444444444, loss: 0.27143772857056725\n",
      "EPOCH: 9, acc: 0.8730158739619784, loss: 0.3855614165465037\n",
      "EPOCH: 10, acc: 0.8640873034795126, loss: 0.30733518799146015\n",
      "tensor([[-2.3714, -8.2880],\n",
      "        [ 9.1261, -4.4484],\n",
      "        [ 0.3704,  0.5511],\n",
      "        [-4.1142, -6.1091],\n",
      "        [ 1.2181, -0.6756],\n",
      "        [ 4.5208, -1.1367],\n",
      "        [ 1.4945,  1.2694]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1]])\n",
      "EPOCH: 11, acc: 0.9007936517397562, loss: 0.2949478692478604\n",
      "EPOCH: 12, acc: 0.8695436517397562, loss: 0.2660144931740231\n",
      "EPOCH: 13, acc: 0.8556547628508674, loss: 0.3334820113248295\n",
      "EPOCH: 14, acc: 0.8358134925365448, loss: 0.3429985460307863\n",
      "EPOCH: 15, acc: 0.8467261923684014, loss: 0.4457776877615187\n",
      "tensor([[ 0.7273, -0.2513],\n",
      "        [ 1.2434, -8.5257],\n",
      "        [ 1.0549,  0.9236],\n",
      "        [ 5.1769, -3.4720],\n",
      "        [ 2.5246, -3.1314],\n",
      "        [ 0.4663,  0.5869],\n",
      "        [ 0.2432, -1.8889]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]])\n",
      "EPOCH: 16, acc: 0.8105158739619784, loss: 0.35332098768817055\n",
      "EPOCH: 17, acc: 0.8645833333333334, loss: 0.2894490443997913\n",
      "EPOCH: 18, acc: 0.866071429517534, loss: 0.3105275829633077\n",
      "EPOCH: 19, acc: 0.8993055555555556, loss: 0.2776760624514686\n",
      "EPOCH: 20, acc: 0.8779761923684014, loss: 0.3227227222588327\n",
      "tensor([[  1.1116,  -1.0387],\n",
      "        [  2.6471,   0.2007],\n",
      "        [ -1.2598, -11.9481],\n",
      "        [  0.7809,  -3.1299],\n",
      "        [  1.8082,  -8.7037],\n",
      "        [  1.5377,  -6.6327],\n",
      "        [  0.7761,   3.2795]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1]])\n",
      "EPOCH: 21, acc: 0.875, loss: 0.3019476731618245\n",
      "EPOCH: 22, acc: 0.90625, loss: 0.2480441853404045\n",
      "EPOCH: 23, acc: 0.8834325406286452, loss: 0.2799349021580484\n",
      "EPOCH: 24, acc: 0.8888888888888888, loss: 0.2701011937525537\n",
      "EPOCH: 25, acc: 0.8834325406286452, loss: 0.2850662171840668\n",
      "tensor([[ 1.2826,  1.2981],\n",
      "        [ 2.5311, -1.3130],\n",
      "        [ 1.9032, -5.2508],\n",
      "        [ 0.7958, -0.0343],\n",
      "        [ 5.3675, -3.8246],\n",
      "        [ 3.2403, -1.6333],\n",
      "        [ 2.8260,  0.4900]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1]])\n",
      "EPOCH: 26, acc: 0.8764880961842008, loss: 0.31343328290515476\n",
      "EPOCH: 27, acc: 0.8938492072953118, loss: 0.24756604433059692\n",
      "EPOCH: 28, acc: 0.8958333333333334, loss: 0.2406292971637514\n",
      "EPOCH: 29, acc: 0.8606150812572904, loss: 0.27755401531855267\n",
      "EPOCH: 30, acc: 0.8819444444444444, loss: 0.2673732083704736\n",
      "tensor([[  2.0061, -16.0965],\n",
      "        [  1.4557,  -0.2513],\n",
      "        [  2.6426,  -0.4773],\n",
      "        [  2.0964,   0.4010],\n",
      "        [  3.5628,   0.1570],\n",
      "        [  2.1688,   1.2368],\n",
      "        [  0.3747,  -3.1298]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "EPOCH: 31, acc: 0.9097222222222222, loss: 0.22279948203100097\n",
      "EPOCH: 32, acc: 0.911210318406423, loss: 0.23740397724840376\n",
      "EPOCH: 33, acc: 0.8903769850730896, loss: 0.2520809579226706\n",
      "EPOCH: 34, acc: 0.8938492072953118, loss: 0.24959078431129456\n",
      "EPOCH: 35, acc: 0.9097222222222222, loss: 0.2456532965103785\n",
      "tensor([[ 0.9644,  4.1532],\n",
      "        [ 0.9478,  2.9974],\n",
      "        [13.0605, -1.5368],\n",
      "        [-0.6650, -7.7523],\n",
      "        [ 1.4333, -1.1079],\n",
      "        [ 1.2351, -5.6747],\n",
      "        [ 1.1532,  1.0784]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "EPOCH: 36, acc: 0.8993055555555556, loss: 0.2260499099890391\n",
      "EPOCH: 37, acc: 0.9166666666666666, loss: 0.21954308657182586\n",
      "EPOCH: 38, acc: 0.9097222222222222, loss: 0.21248661478360495\n",
      "EPOCH: 39, acc: 0.9077380961842008, loss: 0.23947690344519085\n",
      "EPOCH: 40, acc: 0.8953373034795126, loss: 0.22376884064740604\n",
      "tensor([[ 2.3927, -1.4069],\n",
      "        [ 0.4202, -7.2322],\n",
      "        [ 3.0028, -3.6212],\n",
      "        [ 1.4012, -1.1736],\n",
      "        [ 1.4122, -0.3232],\n",
      "        [ 1.4749, -5.9566],\n",
      "        [ 0.9425,  0.6626]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]])\n",
      "EPOCH: 41, acc: 0.9236111111111112, loss: 0.19964861373106638\n",
      "EPOCH: 42, acc: 0.9166666666666666, loss: 0.21605777243773142\n",
      "EPOCH: 43, acc: 0.8988095257017348, loss: 0.2790204824672805\n",
      "EPOCH: 44, acc: 0.9007936517397562, loss: 0.27504116627905106\n",
      "EPOCH: 45, acc: 0.9007936517397562, loss: 0.2712481651041243\n",
      "tensor([[  1.7664,  -0.0943],\n",
      "        [  1.6009,   1.9974],\n",
      "        [  0.6456,  -3.7354],\n",
      "        [ -1.0889,  -2.0180],\n",
      "        [  1.0815,  -0.8337],\n",
      "        [  1.1378,  -1.2238],\n",
      "        [ -3.9850, -14.1047]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]])\n",
      "EPOCH: 46, acc: 0.8764880961842008, loss: 0.2795691556400723\n",
      "EPOCH: 47, acc: 0.9201388888888888, loss: 0.23024726079569924\n",
      "EPOCH: 48, acc: 0.8745039701461792, loss: 0.3323936578300264\n",
      "EPOCH: 49, acc: 0.8903769850730896, loss: 0.2563984559641944\n",
      "EPOCH: 50, acc: 0.8903769850730896, loss: 0.22766701711548698\n",
      "tensor([[-0.2391, -0.7632],\n",
      "        [ 3.5152, -1.7399],\n",
      "        [ 2.0501, -4.5843],\n",
      "        [ 4.3761, -1.5516],\n",
      "        [ 2.3806, -5.0162],\n",
      "        [ 1.6450, -1.2758],\n",
      "        [ 0.5869, -0.5088]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "EPOCH: 51, acc: 0.9409722222222222, loss: 0.19474460557103157\n",
      "EPOCH: 52, acc: 0.8918650812572904, loss: 0.26767833944824004\n",
      "EPOCH: 53, acc: 0.8953373034795126, loss: 0.24102710684140524\n",
      "EPOCH: 54, acc: 0.9146825406286452, loss: 0.24086354590124553\n",
      "EPOCH: 55, acc: 0.8938492072953118, loss: 0.23840165303813088\n",
      "tensor([[ 3.0353, -1.4471],\n",
      "        [-3.1589, -1.8170],\n",
      "        [ 1.5178, -1.0503],\n",
      "        [ 4.0658, -9.3802],\n",
      "        [ 1.4791, -3.3757],\n",
      "        [-4.5444, -3.1735],\n",
      "        [ 1.2070, -0.1372]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1]])\n",
      "EPOCH: 56, acc: 0.8814484145906236, loss: 0.27770161049233544\n",
      "EPOCH: 57, acc: 0.911210318406423, loss: 0.2718733681572808\n",
      "EPOCH: 58, acc: 0.9216269850730896, loss: 0.2204279543624984\n",
      "EPOCH: 59, acc: 0.8918650812572904, loss: 0.33177780773904586\n",
      "EPOCH: 60, acc: 0.9166666666666666, loss: 0.22957594941059747\n",
      "tensor([[ 1.9956, -0.1346],\n",
      "        [ 1.3886, -1.2142],\n",
      "        [ 1.3302, -3.1178],\n",
      "        [ 0.6419,  1.4895],\n",
      "        [ 0.1389,  1.8341],\n",
      "        [ 6.4402, -6.0283],\n",
      "        [ 3.4633, -4.3846]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "EPOCH: 61, acc: 0.9027777777777778, loss: 0.23753421919213402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 62, acc: 0.9201388888888888, loss: 0.22569085326459673\n",
      "EPOCH: 63, acc: 0.8849206368128458, loss: 0.23806856241491106\n",
      "EPOCH: 64, acc: 0.911210318406423, loss: 0.2530073614584075\n",
      "EPOCH: 65, acc: 0.8958333333333334, loss: 0.23456614795658323\n",
      "tensor([[-3.9419e-01,  3.8355e+00],\n",
      "        [ 1.1219e+00, -1.1340e+00],\n",
      "        [ 7.2946e+00, -7.3998e+00],\n",
      "        [-4.2779e-01, -1.5810e+00],\n",
      "        [ 4.9212e+00, -8.6220e+00],\n",
      "        [ 2.7718e+00, -3.4016e+00],\n",
      "        [ 2.1463e-01,  8.1265e-03]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "EPOCH: 66, acc: 0.9201388888888888, loss: 0.19267985224723816\n",
      "EPOCH: 67, acc: 0.9305555555555556, loss: 0.255658561984698\n",
      "EPOCH: 68, acc: 0.9042658739619784, loss: 0.23440636694431305\n",
      "EPOCH: 69, acc: 0.8938492072953118, loss: 0.2546912812524372\n",
      "EPOCH: 70, acc: 0.8903769850730896, loss: 0.2524317767884996\n",
      "tensor([[ 2.3482, -3.8019],\n",
      "        [ 4.0008, -3.4400],\n",
      "        [ 0.5246,  0.5539],\n",
      "        [ 0.5600,  0.3490],\n",
      "        [ 2.1552, -0.7995],\n",
      "        [ 4.2531, -2.4180],\n",
      "        [ 0.7088,  3.4785]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1]])\n",
      "EPOCH: 71, acc: 0.8869047628508674, loss: 0.28888220091660816\n",
      "EPOCH: 72, acc: 0.8903769850730896, loss: 0.26500051551394993\n",
      "EPOCH: 73, acc: 0.8953373034795126, loss: 0.37822331488132477\n",
      "EPOCH: 74, acc: 0.8958333333333334, loss: 0.348315750559171\n",
      "EPOCH: 75, acc: 0.8888888888888888, loss: 0.2693779178791576\n",
      "tensor([[ 0.6536, -0.1860],\n",
      "        [ 6.9398, -3.3879],\n",
      "        [ 7.2690, -4.0030],\n",
      "        [10.6477, -8.7361],\n",
      "        [ 2.8309, -1.0182],\n",
      "        [ 2.1861, -5.0899],\n",
      "        [ 0.0949, -1.3529]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "EPOCH: 76, acc: 0.8764880961842008, loss: 0.32946187257766724\n",
      "EPOCH: 77, acc: 0.8834325406286452, loss: 0.26210331751240623\n",
      "EPOCH: 78, acc: 0.8551587329970466, loss: 0.35179900460773045\n",
      "EPOCH: 79, acc: 0.8784722222222222, loss: 0.2999080825183127\n",
      "EPOCH: 80, acc: 0.8655753996637132, loss: 0.4277411094970173\n",
      "tensor([[-1.7552, -4.1271],\n",
      "        [-0.5996, -2.0940],\n",
      "        [ 1.8440, -5.2702],\n",
      "        [-0.1050, -5.8652],\n",
      "        [ 1.0603, -0.3154],\n",
      "        [-1.4352, -1.0786],\n",
      "        [ 3.0448, -2.0685]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]])\n",
      "EPOCH: 81, acc: 0.8764880961842008, loss: 0.28458596931563485\n",
      "EPOCH: 82, acc: 0.9131944444444444, loss: 0.25753670930862427\n",
      "EPOCH: 83, acc: 0.9007936517397562, loss: 0.25385650826825035\n",
      "EPOCH: 84, acc: 0.9181547628508674, loss: 0.2157970815896988\n",
      "EPOCH: 85, acc: 0.8938492072953118, loss: 0.2723267318473922\n",
      "tensor([[ 0.1159, -0.4196],\n",
      "        [ 4.1073, -2.7192],\n",
      "        [ 1.0829, -5.5333],\n",
      "        [ 1.8630, -0.2016],\n",
      "        [ 0.9969, -3.6170],\n",
      "        [ 5.3575, -8.8610],\n",
      "        [ 0.3688,  1.5388]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "EPOCH: 86, acc: 0.9131944444444444, loss: 0.21217093533939785\n",
      "EPOCH: 87, acc: 0.90625, loss: 0.19930116583903631\n",
      "EPOCH: 88, acc: 0.9042658739619784, loss: 0.22304330435064104\n",
      "EPOCH: 89, acc: 0.8640873034795126, loss: 0.2855341351694531\n",
      "EPOCH: 90, acc: 0.9479166666666666, loss: 0.20845015512572396\n",
      "tensor([[-0.2107, -0.2836],\n",
      "        [ 2.0609, -1.3794],\n",
      "        [ 2.9820, -1.9568],\n",
      "        [ 4.1626, -4.2757],\n",
      "        [ 1.3095, -0.5105],\n",
      "        [ 1.7961, -1.6524],\n",
      "        [-1.6678, -2.5686]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "EPOCH: 91, acc: 0.8938492072953118, loss: 0.22830846077866024\n",
      "EPOCH: 92, acc: 0.8903769850730896, loss: 0.224397458963924\n",
      "EPOCH: 93, acc: 0.8953373034795126, loss: 0.22279457334015104\n",
      "EPOCH: 94, acc: 0.9077380961842008, loss: 0.2373113152053621\n",
      "EPOCH: 95, acc: 0.9201388888888888, loss: 0.1910422332584858\n",
      "tensor([[ 3.3257, -0.3619],\n",
      "        [ 0.7051, -1.0840],\n",
      "        [ 4.4159, -1.4232],\n",
      "        [-3.5373,  9.7503],\n",
      "        [10.4877, -3.7580],\n",
      "        [ 3.1666,  0.4715],\n",
      "        [ 1.7330,  0.0694]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "EPOCH: 96, acc: 0.9181547628508674, loss: 0.23569570398992962\n",
      "EPOCH: 97, acc: 0.8849206368128458, loss: 0.2755068979329533\n",
      "EPOCH: 98, acc: 0.8888888888888888, loss: 0.2396975118252966\n",
      "EPOCH: 99, acc: 0.8958333333333334, loss: 0.20959489792585373\n",
      "EPOCH: 100, acc: 0.911210318406423, loss: 0.19082524379094443\n",
      "tensor([[ 1.7495, -2.0480],\n",
      "        [ 4.1567, -2.9438],\n",
      "        [ 1.4256, -0.5687],\n",
      "        [ 0.3071, -1.7067],\n",
      "        [ 8.6511, -2.3837],\n",
      "        [-0.1644,  0.3656],\n",
      "        [ 1.9423, -1.1278]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "EPOCH: 101, acc: 0.9216269850730896, loss: 0.1729262446363767\n",
      "EPOCH: 102, acc: 0.9166666666666666, loss: 0.2078397340244717\n",
      "EPOCH: 103, acc: 0.9181547628508674, loss: 0.20650681936078602\n",
      "EPOCH: 104, acc: 0.9181547628508674, loss: 0.2691425581773122\n",
      "EPOCH: 105, acc: 0.9007936517397562, loss: 0.22335629330741036\n",
      "tensor([[ 3.5407, -3.1329],\n",
      "        [ 0.6104, -0.6073],\n",
      "        [-3.2226,  1.5397],\n",
      "        [13.1041, -9.3381],\n",
      "        [-0.0766, -0.7744],\n",
      "        [ 4.7442, -8.5895],\n",
      "        [ 2.0286, -4.0426]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "EPOCH: 106, acc: 0.9201388888888888, loss: 0.2962813675403595\n",
      "EPOCH: 107, acc: 0.9007936517397562, loss: 0.21247867577605778\n",
      "EPOCH: 108, acc: 0.9375, loss: 0.16352823749184608\n",
      "EPOCH: 109, acc: 0.9181547628508674, loss: 0.21628082709179985\n",
      "EPOCH: 110, acc: 0.9250992072953118, loss: 0.18160691360632578\n",
      "tensor([[  0.1181,  -0.3297],\n",
      "        [  6.0854, -10.8900],\n",
      "        [  3.3400,  -1.2949],\n",
      "        [  7.6013,  -4.3186],\n",
      "        [  1.3349,  -0.9818],\n",
      "        [  4.5360,  -1.9129],\n",
      "        [  0.2382,  -0.0206]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1]])\n",
      "EPOCH: 111, acc: 0.9077380961842008, loss: 0.19295746005243725\n",
      "EPOCH: 112, acc: 0.9042658739619784, loss: 0.2179937180545595\n",
      "EPOCH: 113, acc: 0.9042658739619784, loss: 0.2037108408080207\n",
      "EPOCH: 114, acc: 0.9375, loss: 0.1545266860889064\n",
      "EPOCH: 115, acc: 0.9409722222222222, loss: 0.16496159633000693\n",
      "tensor([[ 1.6478, -0.7180],\n",
      "        [ 3.5359, -1.3467],\n",
      "        [ 2.3959, -0.8131],\n",
      "        [ 4.0407, -6.5847],\n",
      "        [ 1.2276,  0.8017],\n",
      "        [ 0.8887,  0.8063],\n",
      "        [ 5.8676, -4.1410]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "EPOCH: 116, acc: 0.9375, loss: 0.1612001471221447\n",
      "EPOCH: 117, acc: 0.9146825406286452, loss: 0.2532443590462208\n",
      "EPOCH: 118, acc: 0.9146825406286452, loss: 0.19370256115992865\n",
      "EPOCH: 119, acc: 0.9236111111111112, loss: 0.1871239004863633\n",
      "EPOCH: 120, acc: 0.9131944444444444, loss: 0.1694603268471029\n",
      "tensor([[-1.0123,  3.1558],\n",
      "        [ 1.9518, -1.9002],\n",
      "        [ 7.3277, -8.6439],\n",
      "        [-5.7644, -0.9372],\n",
      "        [ 0.9921, -0.7014],\n",
      "        [ 1.0965, -1.4906],\n",
      "        [ 7.1423, -5.3662]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "EPOCH: 121, acc: 0.9057539701461792, loss: 0.21311862021684647\n",
      "EPOCH: 122, acc: 0.9305555555555556, loss: 0.1657957269085778\n",
      "EPOCH: 123, acc: 0.9092261923684014, loss: 0.23164624803596073\n",
      "EPOCH: 124, acc: 0.9216269850730896, loss: 0.1743499156501558\n",
      "EPOCH: 125, acc: 0.9201388888888888, loss: 0.161689852260881\n",
      "tensor([[ 3.3403, -2.6935],\n",
      "        [ 4.7294, -2.7008],\n",
      "        [ 5.3095, -4.3536],\n",
      "        [ 5.4799, -2.5927],\n",
      "        [ 0.5696, -0.7351],\n",
      "        [-1.8977,  1.2893],\n",
      "        [ 3.3186, -4.0026]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 126, acc: 0.870535714758767, loss: 0.4160245441728168\n",
      "EPOCH: 127, acc: 0.9042658739619784, loss: 0.21738829712073007\n",
      "EPOCH: 128, acc: 0.8988095257017348, loss: 0.2286173320478863\n",
      "EPOCH: 129, acc: 0.9002976218859354, loss: 0.3336373832490709\n",
      "EPOCH: 130, acc: 0.9077380961842008, loss: 0.2618563166922993\n",
      "tensor([[ 2.4489, -1.4530],\n",
      "        [ 3.6335, -3.1248],\n",
      "        [ 3.0651, -2.5491],\n",
      "        [ 0.1629, -0.3140],\n",
      "        [ 0.2568, -0.9927],\n",
      "        [ 1.2122, -0.6772],\n",
      "        [ 6.8082, -2.7440]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "EPOCH: 131, acc: 0.8958333333333334, loss: 0.2352118074066109\n",
      "EPOCH: 132, acc: 0.9181547628508674, loss: 0.19967858658896553\n",
      "EPOCH: 133, acc: 0.9201388888888888, loss: 0.20953111598889032\n",
      "EPOCH: 134, acc: 0.9077380961842008, loss: 0.21970788058307436\n",
      "EPOCH: 135, acc: 0.9375, loss: 0.2250921974579493\n",
      "tensor([[ 3.1057, -2.6260],\n",
      "        [-0.0510, -0.0552],\n",
      "        [-2.0800, -1.3469],\n",
      "        [ 0.9906, -1.6046],\n",
      "        [12.6993, -4.3857],\n",
      "        [-2.0806, -2.9073],\n",
      "        [ 0.4321, -0.4560]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "EPOCH: 136, acc: 0.9340277777777778, loss: 0.15713542844686243\n",
      "EPOCH: 137, acc: 0.9320436517397562, loss: 0.1712454826467567\n",
      "EPOCH: 138, acc: 0.9340277777777778, loss: 0.1899532030026118\n",
      "EPOCH: 139, acc: 0.9236111111111112, loss: 0.18125502227081192\n",
      "EPOCH: 140, acc: 0.9340277777777778, loss: 0.17374317927492988\n",
      "tensor([[ 4.7525, -4.6644],\n",
      "        [ 4.1286, -1.3865],\n",
      "        [-1.2021,  4.7566],\n",
      "        [-3.0451,  0.8764],\n",
      "        [ 3.8531, -2.1028],\n",
      "        [ 5.2365, -0.2820],\n",
      "        [ 1.4646,  0.2153]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "EPOCH: 141, acc: 0.8898809552192688, loss: 0.2213964429166582\n",
      "EPOCH: 142, acc: 0.9146825406286452, loss: 0.22624370538526112\n",
      "EPOCH: 143, acc: 0.9236111111111112, loss: 0.19218782087167105\n",
      "EPOCH: 144, acc: 0.9375, loss: 0.18987458695967993\n",
      "EPOCH: 145, acc: 0.9077380961842008, loss: 0.20850257989433077\n",
      "tensor([[ 5.7803, -3.5420],\n",
      "        [-0.9981, -0.3606],\n",
      "        [10.5353, -5.8417],\n",
      "        [ 1.1660,  0.3542],\n",
      "        [ 1.0919, -0.9037],\n",
      "        [ 6.4528, -2.5240],\n",
      "        [18.6219, -6.6919]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "EPOCH: 146, acc: 0.911210318406423, loss: 0.19690214759773678\n",
      "EPOCH: 147, acc: 0.9320436517397562, loss: 0.20506050520473057\n",
      "EPOCH: 148, acc: 0.9250992072953118, loss: 0.19922497620185217\n",
      "EPOCH: 149, acc: 0.9444444444444444, loss: 0.17570387572050095\n",
      "EPOCH: 150, acc: 0.9146825406286452, loss: 0.20958738608492744\n",
      "tensor([[ 5.7126, -2.8498],\n",
      "        [ 3.9130, -0.8998],\n",
      "        [ 1.8263, -0.3172],\n",
      "        [ 2.6297, -1.1746],\n",
      "        [13.8540, -6.5142],\n",
      "        [ 0.9470,  0.4618],\n",
      "        [ 2.8627,  2.1933]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1]])\n"
     ]
    }
   ],
   "source": [
    "cnn = construct.train(epochs, BATCH_SIZE, train, criterion, 'Adam', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unexpected-complex",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, predictions, weights, acc = construct.get_predictions(BATCH_SIZE, cnn, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "antique-orbit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8478)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labels[:,1] == predictions).float().sum()/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hazardous-buffalo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6957)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labels[:,1] == 0).float().sum()/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "forward-recipient",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prep_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f0c6a318a9f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'plastic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wrong plastic id 3rd image'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mtest_dataset_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-f0c6a318a9f7>\u001b[0m in \u001b[0;36mtest_dataset_class\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#Eventually just read in already cleaned labels sheet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prep_data' is not defined"
     ]
    }
   ],
   "source": [
    "def test_dataset_class():\n",
    "    filename = '../tests/test_assets/test_labels_unclean.csv'\n",
    "    image_dir = '../tests/test_assets/test_images'\n",
    "    \n",
    "    #Eventually just read in already cleaned labels sheet\n",
    "    labels = prep_data(pd.read_csv(filename), image_dir)\n",
    "    \n",
    "    \n",
    "    transform = None\n",
    "    test_dataset = tenX_dataset(labels, image_dir, transform)\n",
    "    \n",
    "    #len() check\n",
    "    length = len(test_dataset)\n",
    "    expect = 5\n",
    "    assert length is expect, f'10x dataset length method failed. Got {length}, should be {expect}'\n",
    "    \n",
    "    #get_item() check\n",
    "    samples = []\n",
    "    keys = ['image', 'plastic','shape','color']\n",
    "    for i in range(len(test_dataset)):\n",
    "        assert test_dataset[i]['image'] is not None, 'Got NoneType instead of image'\n",
    "        isP = test_dataset[i]['plastic']\n",
    "        assert math.isclose(0,isP) or math.isclose(1,isP), f'plastic not 0 or 1, instead is {isP}'\n",
    "        length = len(test_dataset[i]['shape'])\n",
    "        assert length is 4, f'length of shape array not 4, instead is {length}'\n",
    "        samples.append(test_dataset[i])\n",
    "        \n",
    "    shape = samples[0]['shape']\n",
    "    assert math.isclose(shape[2], 1),  f'wrong shape first image, is {shape}'\n",
    "    color = samples[0]['color']\n",
    "    assert math.isclose(color[0], 1), f'wrong color first image, is {color}'\n",
    "    assert math.isclose(samples[4]['plastic'], 1), 'wrong plastic id 3rd image'\n",
    "    \n",
    "test_dataset_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0 - BASE LINE 82% naive and 88% model test set accuracy\n",
    "#1 - 9 output CNN1, 18 output CNN2 87% test vs 77% naive\n",
    "#2 - 3rd linear layer telescoped (12*39*39 -> 2048 -> 256- >2). 93% test, 87% naive\n",
    "#3 - added a convulutional layer, 12 -> 24 no good\n",
    "#2d dropout after convolutions led to predicting all pastics, i also read dropouts after convultions is bad, going to try batch normalizations though\n",
    "#Another paper I read said that non-adaptive optimizers were better for CNN's if thehyperparameters are tunned\n",
    "#tuned correctly but are much slower so I don't want to even try given it takes me 20min to train already\n",
    "#adding batchnormalization after convultions improved training results alot, but not test which is weird since\n",
    "#its supposed to reduce overfitting. Im going to run again overnight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
