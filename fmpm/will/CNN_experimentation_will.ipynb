{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "presidential-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prep\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn\n",
    "import skimage.io\n",
    "import math\n",
    "import random\n",
    "import torchvision.transforms\n",
    "\n",
    "\n",
    "class default(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes CNN. Here we just define layer shapes that we call in the forward func\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels = 3, \n",
    "                               out_channels = 6, \n",
    "                               kernel_size = 5)\n",
    "                \n",
    "        #Convultion layer 2. See above\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels = 6, \n",
    "                               out_channels = 12, \n",
    "                               kernel_size = 5)\n",
    "        \n",
    "        self.fc_1 = torch.nn.Linear(39 * 39 * 12, 256)\n",
    "        self.fc_2 = torch.nn.Linear(256, 2)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Function that performs all the neural network forward calculation i.e.\n",
    "        takes image data from the input of the neural network to the output\n",
    "        \"\"\"\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, kernel_size = 2)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, kernel_size = 4)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = x.view(x.shape[0], -1)  \n",
    "        x = self.fc_1(x) \n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.fc_2(x)    \n",
    "        \n",
    "        return x\n",
    "\n",
    "default_model = default()\n",
    "\n",
    "\n",
    "def calculate_accuracy(y_pred, y):\n",
    "    acc = ((y_pred.argmax(dim=1) == y).float().mean())\n",
    "    return acc\n",
    "\n",
    "\n",
    "def train_iteration(model, iterator, optimizer, criterion, device):\n",
    "    \"\"\"\n",
    "    Training loop. Takes data through NN calculates loss and adjusts NN. Repeat\n",
    "    \"\"\"\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    #Need to add logic to skip iteration if image is None\n",
    "    for sample in iterator:  \n",
    "        image = sample['image'].to(device)\n",
    "        isPlasticRaw = sample['plastic'].to(device)\n",
    "        optimizer.zero_grad()      \n",
    "        y_pred = model(image)\n",
    "        isPlastic = isPlasticRaw.argmax(dim=1)\n",
    "        loss = criterion(y_pred, isPlastic)\n",
    "        acc = calculate_accuracy(y_pred, isPlastic)\n",
    "        loss.backward()    \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator) , epoch_acc / len(iterator), y_pred, isPlasticRaw\n",
    "\n",
    "\n",
    "\n",
    "class default(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes CNN. Here we just define layer shapes that we call in the forward func\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels = 3, \n",
    "                               out_channels = 6, \n",
    "                               kernel_size = 5)\n",
    "                \n",
    "        #Convultion layer 2. See above\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels = 6, \n",
    "                               out_channels = 12, \n",
    "                               kernel_size = 5)\n",
    "        \n",
    "        self.fc_1 = torch.nn.Linear(39 * 39 * 12, 256)\n",
    "        self.fc_2 = torch.nn.Linear(256, 2)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Function that performs all the neural network forward calculation i.e.\n",
    "        takes image data from the input of the neural network to the output\n",
    "        \"\"\"\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, kernel_size = 2)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, kernel_size = 4)\n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = x.view(x.shape[0], -1)  \n",
    "        x = self.fc_1(x) \n",
    "        x = torch.nn.functional.leaky_relu(x)\n",
    "        x = self.fc_2(x)    \n",
    "        \n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "default_model = default()\n",
    "default_optimizer = torch.optim.Adam(default_model.parameters(), lr=.002)\n",
    "\n",
    "def train(epochs, batch_size, dataset, criterion,\n",
    "          optimizer=default_optimizer,\n",
    "          model=default_model,\n",
    "          device=torch.device('cpu')):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=.002)\n",
    "\n",
    "    \n",
    "    train_iterator = torch.utils.data.DataLoader(dataset, \n",
    "                                 shuffle = True, \n",
    "                                 batch_size = batch_size)\n",
    "    model.to(device)\n",
    "    criterion.to(device)\n",
    "    \n",
    "    for epoch in range(epochs+1):\n",
    "        train_loss, train_acc, y_pred, target = (\n",
    "            train_iteration(model, train_iterator, optimizer, criterion, device))\n",
    "        print(f'EPOCH: {epoch}, acc: {train_acc}, loss: {train_loss}')\n",
    "        if epoch % 5 is 0:\n",
    "            print(y_pred)\n",
    "            print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sharp-harvard",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Will/GradSchool/CHEME/Project/FmPM/fmpm/will/prep.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  identification[i] = False\n",
      "/Users/Will/GradSchool/CHEME/Project/FmPM/fmpm/will/prep.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  identification[i] = True\n"
     ]
    }
   ],
   "source": [
    "image_dir = 'data/10x'\n",
    "labels_file = 'data/me.csv'\n",
    "\n",
    "DATA = prep.prep_data(pd.read_csv(labels_file), image_dir)\n",
    "\n",
    "transforms = torchvision.transforms.Compose([\n",
    "                            torchvision.transforms.ToPILImage(),\n",
    "                            torchvision.transforms.RandomRotation((-180,180)),\n",
    "                            torchvision.transforms.CenterCrop((325)),\n",
    "                            torchvision.transforms.ToTensor()\n",
    "                                      ])\n",
    "\n",
    "train_data = prep.tenX_dataset(DATA, 'data/10x', transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "greater-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring iterator. The thing that will loop through our dataset.\n",
    "\n",
    "train_data = prep.tenX_dataset(DATA, 'data/10x', transform =transforms)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=.002)\n",
    "BATCH_SIZE = 10\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cooperative-context",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0, acc: 0.8125447996201054, loss: 0.4519150067240961\n",
      "tensor([[ 0.6090, -0.8797],\n",
      "        [ 0.5215, -0.7523],\n",
      "        [ 0.7102, -1.0227],\n",
      "        [ 0.5189, -0.7556],\n",
      "        [ 0.6566, -0.9649],\n",
      "        [ 0.8082, -1.1734],\n",
      "        [ 0.5143, -0.7490],\n",
      "        [ 0.4659, -0.6778],\n",
      "        [ 0.5205, -0.7503]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "EPOCH: 1, acc: 0.8376344000139544, loss: 0.43134462496926707\n",
      "EPOCH: 2, acc: 0.8064516109804953, loss: 0.4453781021218146\n",
      "EPOCH: 3, acc: 0.8182795701488372, loss: 0.4440372329085104\n",
      "EPOCH: 4, acc: 0.8415770569155293, loss: 0.5060019998721057\n",
      "EPOCH: 5, acc: 0.8354838721213802, loss: 0.4498979713647596\n",
      "tensor([[ 1.1543, -0.9445],\n",
      "        [ 0.9911, -0.8002],\n",
      "        [ 0.9945, -0.8325],\n",
      "        [ 0.8983, -0.7509],\n",
      "        [ 0.9387, -0.7889],\n",
      "        [ 1.0886, -0.8640],\n",
      "        [ 0.3604, -0.3700],\n",
      "        [ 0.8727, -0.7258],\n",
      "        [ 1.1737, -0.9201]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n",
      "EPOCH: 6, acc: 0.8387096716511634, loss: 0.3900296471772655\n",
      "EPOCH: 7, acc: 0.8573476614490632, loss: 0.36937016729385624\n",
      "EPOCH: 8, acc: 0.8448028641362344, loss: 0.45112897984443173\n",
      "EPOCH: 9, acc: 0.8476702455551394, loss: 0.4099905784091642\n",
      "EPOCH: 10, acc: 0.8512544728094532, loss: 0.4292755927289686\n",
      "tensor([[ 0.2198, -0.3749],\n",
      "        [-0.3451,  0.1903],\n",
      "        [ 0.2787, -0.5301],\n",
      "        [ 0.4778, -0.8001],\n",
      "        [ 0.3856, -0.6357],\n",
      "        [ 0.2153, -0.4083],\n",
      "        [ 0.3750, -0.6007],\n",
      "        [-0.3424,  0.0062],\n",
      "        [ 0.4891, -0.7868]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]])\n",
      "EPOCH: 11, acc: 0.8577060853281329, loss: 0.3764845180896021\n",
      "EPOCH: 12, acc: 0.8508960546985749, loss: 0.3799601313808272\n",
      "EPOCH: 13, acc: 0.8544802742619668, loss: 0.3670326104808238\n",
      "EPOCH: 14, acc: 0.8677419289465873, loss: 0.3481634987458106\n",
      "EPOCH: 15, acc: 0.8702508903318836, loss: 0.32517810478325815\n",
      "tensor([[ 1.3255, -1.4867],\n",
      "        [ 0.8527, -1.0785],\n",
      "        [ 1.2261, -1.4114],\n",
      "        [ 1.3502, -1.5441],\n",
      "        [ 1.3158, -1.5543],\n",
      "        [ 1.5466, -1.7419],\n",
      "        [ 0.4983, -0.6677],\n",
      "        [ 1.7031, -1.9208],\n",
      "        [ 1.2833, -1.5213]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-765d5f45ba98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/GradSchool/CHEME/Project/FmPM/fmpm/will/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, batch_size, dataset, criterion, optimizer, model, device)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         train_loss, train_acc, y_pred, target = (\n\u001b[0;32m--> 104\u001b[0;31m             train_iteration(model, train_iterator, optimizer, criterion, device))\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'EPOCH: {epoch}, acc: {train_acc}, loss: {train_loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GradSchool/CHEME/Project/FmPM/fmpm/will/model.py\u001b[0m in \u001b[0;36mtrain_iteration\u001b[0;34m(model, iterator, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0misPlasticRaw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'plastic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0misPlastic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misPlasticRaw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misPlastic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GradSchool/CHEME/Project/FmPM/fmpm/will/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(epochs, BATCH_SIZE, train_data, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataset_class():\n",
    "    filename = '../tests/test_assets/test_labels_unclean.csv'\n",
    "    image_dir = '../tests/test_assets/test_images'\n",
    "    \n",
    "    #Eventually just read in already cleaned labels sheet\n",
    "    labels = prep_data(pd.read_csv(filename), image_dir)\n",
    "    \n",
    "    \n",
    "    transform = None\n",
    "    test_dataset = tenX_dataset(labels, image_dir, transform)\n",
    "    \n",
    "    #len() check\n",
    "    length = len(test_dataset)\n",
    "    expect = 5\n",
    "    assert length is expect, f'10x dataset length method failed. Got {length}, should be {expect}'\n",
    "    \n",
    "    #get_item() check\n",
    "    samples = []\n",
    "    keys = ['image', 'plastic','shape','color']\n",
    "    for i in range(len(test_dataset)):\n",
    "        assert test_dataset[i]['image'] is not None, 'Got NoneType instead of image'\n",
    "        isP = test_dataset[i]['plastic']\n",
    "        assert math.isclose(0,isP) or math.isclose(1,isP), f'plastic not 0 or 1, instead is {isP}'\n",
    "        length = len(test_dataset[i]['shape'])\n",
    "        assert length is 4, f'length of shape array not 4, instead is {length}'\n",
    "        samples.append(test_dataset[i])\n",
    "        \n",
    "    shape = samples[0]['shape']\n",
    "    assert math.isclose(shape[2], 1),  f'wrong shape first image, is {shape}'\n",
    "    color = samples[0]['color']\n",
    "    assert math.isclose(color[0], 1), f'wrong color first image, is {color}'\n",
    "    assert math.isclose(samples[4]['plastic'], 1), 'wrong plastic id 3rd image'\n",
    "    \n",
    "test_dataset_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-marking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
